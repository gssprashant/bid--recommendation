{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba297ec",
   "metadata": {},
   "source": [
    "# Bid Recommendation Model\n",
    "\n",
    "This notebook implements a machine learning model for bid recommendations using XGBoost. The model predicts optimal bid amounts based on historical bid data and project characteristics.\n",
    "\n",
    "## Features\n",
    "- Data validation and preprocessing\n",
    "- Feature engineering with time-based features\n",
    "- XGBoost regression model\n",
    "- Cross-validation and model evaluation\n",
    "- Model persistence for deployment\n",
    "\n",
    "## Requirements\n",
    "- Python 3.8+\n",
    "- pandas\n",
    "- numpy\n",
    "- scikit-learn\n",
    "- xgboost\n",
    "\n",
    "## Input Data Format\n",
    "The model expects a CSV file with the following required columns:\n",
    "- `BidDate`: Date of the bid\n",
    "- `BidAmount`: Numerical bid amount\n",
    "- `WinStatus`: Binary indicator (0/1) for bid success\n",
    "\n",
    "Optional columns that improve model performance:\n",
    "- `ProjectType`: Type of the project\n",
    "- `Location`: Project location\n",
    "- `ClientType`: Type of client\n",
    "- `EstimatedCost`: Estimated project cost\n",
    "- `CompetitorCount`: Number of competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "726cd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a28bd5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directories created:\n",
      "- models: c:\\Users\\prash\\bid--recommendation\\GSS Bid Models\\models\n",
      "- data: c:\\Users\\prash\\bid--recommendation\\GSS Bid Models\\data\n",
      "- config: c:\\Users\\prash\\bid--recommendation\\GSS Bid Models\\config\n",
      "- model_file: c:\\Users\\prash\\bid--recommendation\\GSS Bid Models\\models\\xgb_regressor.pkl\n",
      "- encoders_file: c:\\Users\\prash\\bid--recommendation\\GSS Bid Models\\models\\encoders.pkl\n",
      "- metadata_file: c:\\Users\\prash\\bid--recommendation\\GSS Bid Models\\config\\metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Project Setup\n",
    "def setup_project():\n",
    "    \"\"\"Setup project configuration and directory structure\"\"\"\n",
    "    config = {\n",
    "        'data': {\n",
    "            'required_cols': ['BidDate', 'BidAmount', 'WinStatus'],\n",
    "            'optional_cols': ['ProjectType', 'Location', 'ClientType', 'EstimatedCost', 'CompetitorCount'],\n",
    "            'categorical_cols': ['ProjectType', 'Location', 'ClientType']\n",
    "        },\n",
    "        'model': {\n",
    "            'name': 'xgb_regressor',\n",
    "            'params': {\n",
    "                'n_estimators': 200,\n",
    "                'learning_rate': 0.05,\n",
    "                'max_depth': 6,\n",
    "                'min_child_weight': 2,\n",
    "                'subsample': 0.8,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'random_state': 42\n",
    "            },\n",
    "            'cv_folds': 5,\n",
    "            'test_size': 0.2\n",
    "        },\n",
    "        'paths': {}\n",
    "    }\n",
    "    \n",
    "    # Setup directories\n",
    "    base_dir = Path().absolute()\n",
    "    directories = {\n",
    "        'models': base_dir / 'models',\n",
    "        'data': base_dir / 'data',\n",
    "        'config': base_dir / 'config'\n",
    "    }\n",
    "    \n",
    "    # Create directories\n",
    "    for name, path in directories.items():\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        config['paths'][name] = path\n",
    "        \n",
    "    # Add file paths\n",
    "    config['paths'].update({\n",
    "        'model_file': directories['models'] / 'xgb_regressor.pkl',\n",
    "        'encoders_file': directories['models'] / 'encoders.pkl',\n",
    "        'metadata_file': directories['config'] / 'metadata.json'\n",
    "    })\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Create project configuration\n",
    "config = setup_project()\n",
    "print(\"Project directories created:\")\n",
    "for name, path in config['paths'].items():\n",
    "    print(f\"- {name}: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05439e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data saved to sample_bid_data.csv\n",
      "Loading data from sample_bid_data.csv\n",
      "\n",
      "Dataset Statistics:\n",
      "Number of records: 1,000\n",
      "Date range: 2024-01-01 00:00:00 to 2026-09-26 00:00:00\n",
      "Average bid amount: $99,880.61\n",
      "Win rate: 36.9%\n",
      "\n",
      "Optional columns present:\n",
      "- EstimatedCost\n",
      "- Location\n",
      "- ProjectType\n",
      "- CompetitorCount\n",
      "- ClientType\n"
     ]
    }
   ],
   "source": [
    "# Data Loading and Validation\n",
    "class BidDataLoader:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.required_cols = config['data']['required_cols']\n",
    "        self.optional_cols = config['data']['optional_cols']\n",
    "        \n",
    "    def validate_columns(self, df):\n",
    "        \"\"\"Validate required columns exist\"\"\"\n",
    "        missing_cols = [col for col in self.required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        return True\n",
    "    \n",
    "    def process_dates(self, df):\n",
    "        \"\"\"Convert and validate date column\"\"\"\n",
    "        try:\n",
    "            df['BidDate'] = pd.to_datetime(df['BidDate'])\n",
    "            df = df.sort_values('BidDate').reset_index(drop=True)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error processing dates: {str(e)}\")\n",
    "        return df\n",
    "    \n",
    "    def validate_data(self, df):\n",
    "        \"\"\"Perform data validation checks\"\"\"\n",
    "        # Check for empty dataframe\n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"Empty dataframe\")\n",
    "            \n",
    "        # Check for missing values in required columns\n",
    "        missing = df[self.required_cols].isnull().sum()\n",
    "        if missing.any():\n",
    "            print(\"Warning: Missing values in required columns:\")\n",
    "            print(missing[missing > 0])\n",
    "            \n",
    "        # Validate numeric columns\n",
    "        if not pd.to_numeric(df['BidAmount'], errors='coerce').notnull().all():\n",
    "            raise ValueError(\"BidAmount contains non-numeric values\")\n",
    "            \n",
    "        # Validate binary win status\n",
    "        if not df['WinStatus'].isin([0, 1]).all():\n",
    "            raise ValueError(\"WinStatus must be binary (0 or 1)\")\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def print_statistics(self, df):\n",
    "        \"\"\"Print basic dataset statistics\"\"\"\n",
    "        print(\"\\nDataset Statistics:\")\n",
    "        print(f\"Number of records: {len(df):,}\")\n",
    "        print(f\"Date range: {df['BidDate'].min()} to {df['BidDate'].max()}\")\n",
    "        print(f\"Average bid amount: ${df['BidAmount'].mean():,.2f}\")\n",
    "        print(f\"Win rate: {(df['WinStatus'].mean() * 100):.1f}%\")\n",
    "        \n",
    "        if set(self.optional_cols) & set(df.columns):\n",
    "            print(\"\\nOptional columns present:\")\n",
    "            for col in set(self.optional_cols) & set(df.columns):\n",
    "                print(f\"- {col}\")\n",
    "    \n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"Load and validate bid data\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading data from {file_path}\")\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Validate and process data\n",
    "            self.validate_columns(df)\n",
    "            df = self.process_dates(df)\n",
    "            self.validate_data(df)\n",
    "            self.print_statistics(df)\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Create sample data for testing\n",
    "def create_sample_data(n_samples=1000):\n",
    "    \"\"\"Create a sample dataset for testing\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate dates\n",
    "    start_date = pd.Timestamp('2024-01-01')\n",
    "    dates = pd.date_range(start=start_date, periods=n_samples, freq='D')\n",
    "    \n",
    "    # Sample data parameters\n",
    "    project_types = ['Commercial', 'Residential', 'Industrial', 'Infrastructure']\n",
    "    locations = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
    "    client_types = ['Government', 'Private', 'Corporate', 'Non-Profit']\n",
    "    \n",
    "    # Generate data\n",
    "    df = pd.DataFrame({\n",
    "        'BidDate': dates,\n",
    "        'ProjectType': np.random.choice(project_types, size=n_samples),\n",
    "        'Location': np.random.choice(locations, size=n_samples),\n",
    "        'ClientType': np.random.choice(client_types, size=n_samples),\n",
    "        'BidAmount': np.random.lognormal(mean=11, sigma=1, size=n_samples),\n",
    "        'EstimatedCost': np.random.lognormal(mean=10.8, sigma=1, size=n_samples),\n",
    "        'CompetitorCount': np.random.randint(1, 8, size=n_samples)\n",
    "    })\n",
    "    \n",
    "    # Generate win status\n",
    "    prob_win = 1 / (1 + np.exp(-(\n",
    "        -0.3  # Base rate\n",
    "        + 0.2 * (df['BidAmount'] < df['EstimatedCost']).astype(int)\n",
    "        - 0.1 * df['CompetitorCount']\n",
    "        + np.random.normal(0, 0.5, n_samples)\n",
    "    )))\n",
    "    df['WinStatus'] = (np.random.random(n_samples) < prob_win).astype(int)\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = Path('sample_bid_data.csv')\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Sample data saved to {csv_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create sample data and load it\n",
    "df = create_sample_data(n_samples=1000)\n",
    "loader = BidDataLoader(config)\n",
    "df = loader.load_data('sample_bid_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3e39a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Matrix Info:\n",
      "Number of features: 18\n",
      "\n",
      "Feature list:\n",
      "- ProjectType\n",
      "- Location\n",
      "- ClientType\n",
      "- Year\n",
      "- Month\n",
      "- DayOfWeek\n",
      "- Quarter\n",
      "- RollingMeanBid_7d\n",
      "- RollingWinRate_7d\n",
      "- RollingCostRatio_7d\n",
      "- RollingMeanBid_30d\n",
      "- RollingWinRate_30d\n",
      "- RollingCostRatio_30d\n",
      "- RollingMeanBid_90d\n",
      "- RollingWinRate_90d\n",
      "- RollingCostRatio_90d\n",
      "- EstimatedCost\n",
      "- CompetitorCount\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "class FeatureEngineer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.categorical_cols = config['data']['categorical_cols']\n",
    "        self.encoders = {}\n",
    "        \n",
    "    def create_time_features(self, df):\n",
    "        \"\"\"Create time-based features\"\"\"\n",
    "        df_time = df.copy()\n",
    "        \n",
    "        # Basic time features\n",
    "        df_time['Year'] = df_time['BidDate'].dt.year\n",
    "        df_time['Month'] = df_time['BidDate'].dt.month\n",
    "        df_time['DayOfWeek'] = df_time['BidDate'].dt.dayofweek\n",
    "        df_time['Quarter'] = df_time['BidDate'].dt.quarter\n",
    "        \n",
    "        # Rolling windows\n",
    "        windows = [7, 30, 90]\n",
    "        for window in windows:\n",
    "            # Rolling statistics\n",
    "            df_time[f'RollingMeanBid_{window}d'] = (\n",
    "                df_time['BidAmount']\n",
    "                .rolling(window=window, min_periods=1)\n",
    "                .mean()\n",
    "            )\n",
    "            df_time[f'RollingWinRate_{window}d'] = (\n",
    "                df_time['WinStatus']\n",
    "                .rolling(window=window, min_periods=1)\n",
    "                .mean()\n",
    "            )\n",
    "            \n",
    "            if 'EstimatedCost' in df_time.columns:\n",
    "                df_time[f'RollingCostRatio_{window}d'] = (\n",
    "                    df_time['BidAmount'] / df_time['EstimatedCost']\n",
    "                ).rolling(window=window, min_periods=1).mean()\n",
    "        \n",
    "        return df_time\n",
    "    \n",
    "    def encode_categoricals(self, df, train=True):\n",
    "        \"\"\"Encode categorical variables\"\"\"\n",
    "        df_encoded = df.copy()\n",
    "        \n",
    "        for col in self.categorical_cols:\n",
    "            if col in df.columns:\n",
    "                if train:\n",
    "                    self.encoders[col] = LabelEncoder()\n",
    "                    df_encoded[col] = self.encoders[col].fit_transform(df[col].fillna('MISSING'))\n",
    "                else:\n",
    "                    # Handle unseen categories in test data\n",
    "                    df_encoded[col] = df[col].fillna('MISSING')\n",
    "                    df_encoded[col] = df_encoded[col].map(\n",
    "                        dict(zip(self.encoders[col].classes_, range(len(self.encoders[col].classes_))))\n",
    "                    ).fillna(-1)\n",
    "        \n",
    "        return df_encoded\n",
    "    \n",
    "    def create_feature_matrix(self, df, train=True):\n",
    "        \"\"\"Create complete feature matrix\"\"\"\n",
    "        try:\n",
    "            # 1. Create time features\n",
    "            df_features = self.create_time_features(df)\n",
    "            \n",
    "            # 2. Encode categorical variables\n",
    "            df_features = self.encode_categoricals(df_features, train)\n",
    "            \n",
    "            # 3. Combine all features\n",
    "            feature_cols = (\n",
    "                self.categorical_cols +  # Categorical columns\n",
    "                ['Year', 'Month', 'DayOfWeek', 'Quarter'] +  # Time features\n",
    "                [col for col in df_features.columns if 'Rolling' in col]  # Rolling features\n",
    "            )\n",
    "            \n",
    "            # 4. Add optional numeric features\n",
    "            optional_numeric = ['EstimatedCost', 'CompetitorCount']\n",
    "            feature_cols.extend([col for col in optional_numeric if col in df_features.columns])\n",
    "            \n",
    "            # 5. Create X matrix and y vector\n",
    "            X = df_features[feature_cols].copy()\n",
    "            y = df_features['BidAmount']\n",
    "            \n",
    "            # 6. Handle missing values\n",
    "            X = X.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "            \n",
    "            return X, y, feature_cols\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in feature engineering: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Create feature matrices\n",
    "engineer = FeatureEngineer(config)\n",
    "X, y, feature_cols = engineer.create_feature_matrix(df, train=True)\n",
    "\n",
    "print(\"\\nFeature Matrix Info:\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(\"\\nFeature list:\")\n",
    "for col in feature_cols:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a12abfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 5-fold time series cross-validation\n",
      "\n",
      "Fold 1 Results:\n",
      "RMSE: $147,376.87\n",
      "MAE: $83,233.39\n",
      "R2: 0.013\n",
      "\n",
      "Fold 1 Results:\n",
      "RMSE: $147,376.87\n",
      "MAE: $83,233.39\n",
      "R2: 0.013\n",
      "\n",
      "Fold 2 Results:\n",
      "RMSE: $99,717.50\n",
      "MAE: $72,873.80\n",
      "R2: -0.330\n",
      "\n",
      "Fold 2 Results:\n",
      "RMSE: $99,717.50\n",
      "MAE: $72,873.80\n",
      "R2: -0.330\n",
      "\n",
      "Fold 3 Results:\n",
      "RMSE: $150,062.55\n",
      "MAE: $90,116.83\n",
      "R2: 0.088\n",
      "\n",
      "Fold 3 Results:\n",
      "RMSE: $150,062.55\n",
      "MAE: $90,116.83\n",
      "R2: 0.088\n",
      "\n",
      "Fold 4 Results:\n",
      "RMSE: $104,019.00\n",
      "MAE: $72,321.83\n",
      "R2: -0.006\n",
      "\n",
      "Fold 4 Results:\n",
      "RMSE: $104,019.00\n",
      "MAE: $72,321.83\n",
      "R2: -0.006\n",
      "\n",
      "Fold 5 Results:\n",
      "RMSE: $122,459.38\n",
      "MAE: $78,375.41\n",
      "R2: 0.063\n",
      "\n",
      "Cross-validation Average Results:\n",
      "Average RMSE: $124,727.06 ± $21,044.45\n",
      "Average MAE: $79,384.25 ± $6,682.60\n",
      "Average R2: -0.034 ± 0.151\n",
      "\n",
      "Training final model on full dataset...\n",
      "\n",
      "Fold 5 Results:\n",
      "RMSE: $122,459.38\n",
      "MAE: $78,375.41\n",
      "R2: 0.063\n",
      "\n",
      "Cross-validation Average Results:\n",
      "Average RMSE: $124,727.06 ± $21,044.45\n",
      "Average MAE: $79,384.25 ± $6,682.60\n",
      "Average R2: -0.034 ± 0.151\n",
      "\n",
      "Training final model on full dataset...\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                 feature  importance\n",
      "0            ProjectType    0.109250\n",
      "11    RollingWinRate_30d    0.099702\n",
      "7      RollingMeanBid_7d    0.087458\n",
      "3                   Year    0.064197\n",
      "17       CompetitorCount    0.058310\n",
      "15  RollingCostRatio_90d    0.055414\n",
      "13    RollingMeanBid_90d    0.053378\n",
      "9    RollingCostRatio_7d    0.050357\n",
      "10    RollingMeanBid_30d    0.050243\n",
      "12  RollingCostRatio_30d    0.050090\n",
      "Model saved to c:\\Users\\prash\\bid--recommendation\\GSS Bid Models\\models\\xgb_regressor.pkl\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                 feature  importance\n",
      "0            ProjectType    0.109250\n",
      "11    RollingWinRate_30d    0.099702\n",
      "7      RollingMeanBid_7d    0.087458\n",
      "3                   Year    0.064197\n",
      "17       CompetitorCount    0.058310\n",
      "15  RollingCostRatio_90d    0.055414\n",
      "13    RollingMeanBid_90d    0.053378\n",
      "9    RollingCostRatio_7d    0.050357\n",
      "10    RollingMeanBid_30d    0.050243\n",
      "12  RollingCostRatio_30d    0.050090\n",
      "Model saved to c:\\Users\\prash\\bid--recommendation\\GSS Bid Models\\models\\xgb_regressor.pkl\n"
     ]
    }
   ],
   "source": [
    "# Model Training and Evaluation\n",
    "class BidModel:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model_params = config['model']['params']\n",
    "        self.cv_folds = config['model']['cv_folds']\n",
    "        self.model = None\n",
    "        self.cv_scores = {\n",
    "            'rmse': [],\n",
    "            'mae': [],\n",
    "            'r2': []\n",
    "        }\n",
    "        \n",
    "    def train_with_cv(self, X, y):\n",
    "        \"\"\"Train model with cross-validation\"\"\"\n",
    "        try:\n",
    "            # Initialize time-series cross-validation\n",
    "            tscv = TimeSeriesSplit(n_splits=self.cv_folds)\n",
    "            \n",
    "            print(f\"Training with {self.cv_folds}-fold time series cross-validation\")\n",
    "            \n",
    "            for fold, (train_idx, test_idx) in enumerate(tscv.split(X), 1):\n",
    "                # Split data\n",
    "                X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "                y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "                \n",
    "                # Initialize and train model\n",
    "                model = XGBRegressor(**self.model_params)\n",
    "                model.fit(\n",
    "                    X_train, y_train,\n",
    "                    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                # Make predictions\n",
    "                y_pred = model.predict(X_test)\n",
    "                y_pred = np.maximum(y_pred, 0)  # Ensure non-negative predictions\n",
    "                \n",
    "                # Calculate metrics\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                r2 = r2_score(y_test, y_pred)\n",
    "                \n",
    "                # Store scores\n",
    "                self.cv_scores['rmse'].append(rmse)\n",
    "                self.cv_scores['mae'].append(mae)\n",
    "                self.cv_scores['r2'].append(r2)\n",
    "                \n",
    "                print(f\"\\nFold {fold} Results:\")\n",
    "                print(f\"RMSE: ${rmse:,.2f}\")\n",
    "                print(f\"MAE: ${mae:,.2f}\")\n",
    "                print(f\"R2: {r2:.3f}\")\n",
    "            \n",
    "            # Print average scores\n",
    "            print(\"\\nCross-validation Average Results:\")\n",
    "            print(f\"Average RMSE: ${np.mean(self.cv_scores['rmse']):,.2f} ± ${np.std(self.cv_scores['rmse']):,.2f}\")\n",
    "            print(f\"Average MAE: ${np.mean(self.cv_scores['mae']):,.2f} ± ${np.std(self.cv_scores['mae']):,.2f}\")\n",
    "            print(f\"Average R2: {np.mean(self.cv_scores['r2']):.3f} ± {np.std(self.cv_scores['r2']):.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in cross-validation: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def train_final_model(self, X, y):\n",
    "        \"\"\"Train final model on full dataset\"\"\"\n",
    "        try:\n",
    "            print(\"\\nTraining final model on full dataset...\")\n",
    "            \n",
    "            self.model = XGBRegressor(**self.model_params)\n",
    "            self.model.fit(X, y)\n",
    "            \n",
    "            # Calculate feature importance\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': X.columns,\n",
    "                'importance': self.model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(\"\\nTop 10 Most Important Features:\")\n",
    "            print(importance_df.head(10))\n",
    "            \n",
    "            return importance_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training final model: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save trained model\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained yet\")\n",
    "            \n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self.model, f)\n",
    "        print(f\"Model saved to {path}\")\n",
    "\n",
    "# Train and evaluate model\n",
    "model = BidModel(config)\n",
    "model.train_with_cv(X, y)\n",
    "importance_df = model.train_final_model(X, y)\n",
    "\n",
    "# Save model\n",
    "model.save_model(config['paths']['model_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27ee921c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted bid amount: $102,279.71\n",
      "\n",
      "Metadata saved to c:\\Users\\prash\\bid--recommendation\\GSS Bid Models\\config\\metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Model Deployment and Prediction\n",
    "class BidPredictor:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.engineer = None\n",
    "        self.feature_cols = None\n",
    "        \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load trained model\"\"\"\n",
    "        with open(model_path, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "    \n",
    "    def setup(self, model_path, engineer, feature_cols):\n",
    "        \"\"\"Setup predictor with model and feature engineering\"\"\"\n",
    "        self.load_model(model_path)\n",
    "        self.engineer = engineer\n",
    "        self.feature_cols = feature_cols\n",
    "    \n",
    "    def predict(self, bid_data):\n",
    "        \"\"\"Make predictions for new bid data\"\"\"\n",
    "        try:\n",
    "            # Convert to dataframe if single row\n",
    "            if isinstance(bid_data, dict):\n",
    "                bid_data = pd.DataFrame([bid_data])\n",
    "            \n",
    "            # For prediction, we only need BidDate and optional columns\n",
    "            required_for_pred = ['BidDate']  # Modified to only require date\n",
    "            missing_cols = [col for col in required_for_pred if col not in bid_data.columns]\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing required columns for prediction: {missing_cols}\")\n",
    "            \n",
    "            # Convert BidDate to datetime\n",
    "            bid_data = bid_data.copy()\n",
    "            bid_data['BidDate'] = pd.to_datetime(bid_data['BidDate'])\n",
    "            \n",
    "            # Add dummy BidAmount and WinStatus for feature engineering\n",
    "            if 'BidAmount' not in bid_data.columns:\n",
    "                bid_data['BidAmount'] = 0  # Dummy value\n",
    "            if 'WinStatus' not in bid_data.columns:\n",
    "                bid_data['WinStatus'] = 0  # Dummy value\n",
    "            \n",
    "            # Process features\n",
    "            X_new, _, _ = self.engineer.create_feature_matrix(bid_data, train=False) # type: ignore\n",
    "            \n",
    "            # Ensure all feature columns exist\n",
    "            # Ensure feature_cols configured\n",
    "            if not self.feature_cols:\n",
    "                raise ValueError(\"Predictor not configured with feature_cols\")\n",
    "            \n",
    "            # Add any missing feature columns with zeros\n",
    "            for col in self.feature_cols:\n",
    "                if col not in X_new.columns:\n",
    "                    X_new[col] = 0\n",
    "            \n",
    "            # Reorder columns to match training feature order\n",
    "            X_new = X_new[self.feature_cols]\n",
    "            \n",
    "            # Align dtypes to original training X if available to avoid dtype mismatches\n",
    "            try:\n",
    "                if 'X' in globals() and isinstance(X, pd.DataFrame):\n",
    "                    for col in X_new.columns:\n",
    "                        if col in X.columns:\n",
    "                            try:\n",
    "                                X_new[col] = X_new[col].astype(X[col].dtype)\n",
    "                            except Exception:\n",
    "                                # fallback: coerce numeric where possible\n",
    "                                # Try to coerce to numeric only if original column is numeric\n",
    "                                if pd.api.types.is_numeric_dtype(X[col].dtype):\n",
    "                                    X_new[col] = pd.to_numeric(X_new[col], errors='coerce')\n",
    "                                    # attempt to restore original integer dtype if possible\n",
    "                                    try:\n",
    "                                        X_new[col] = X_new[col].astype(X[col].dtype)\n",
    "                                    except Exception:\n",
    "                                        pass\n",
    "                                else:\n",
    "                                    # For non-numeric originals, attempt a safe cast, otherwise leave as-is\n",
    "                                    try:\n",
    "                                        X_new[col] = X_new[col].astype(X[col].dtype)\n",
    "                                    except Exception:\n",
    "                                        pass\n",
    "                else:\n",
    "                    X_new = X_new.apply(pd.to_numeric, errors='ignore')\n",
    "            except Exception:\n",
    "                # If any unexpected issue occurs, continue with best-effort X_new\n",
    "                pass\n",
    "            \n",
    "            # Make prediction\n",
    "            # Validate model loaded and locate callable predictor\n",
    "            if self.model is None:\n",
    "                raise ValueError(\"No model loaded. Call setup() with a valid model file.\")\n",
    "            \n",
    "            predictor_obj = None\n",
    "            # Direct predict method on the loaded object\n",
    "            if hasattr(self.model, \"predict\") and callable(self.model.predict):\n",
    "                predictor_obj = self.model\n",
    "            else:\n",
    "                # Common wrapper attribute names to search for an underlying estimator\n",
    "                for attr in (\"estimator\", \"best_estimator_\", \"model\", \"regressor\", \"pipeline\", \"clf\"):\n",
    "                    if hasattr(self.model, attr):\n",
    "                        candidate = getattr(self.model, attr)\n",
    "                        if hasattr(candidate, \"predict\") and callable(candidate.predict):\n",
    "                            predictor_obj = candidate\n",
    "                            break\n",
    "                # If model was saved as a dict\n",
    "                if predictor_obj is None and isinstance(self.model, dict):\n",
    "                    for key in (\"model\", \"estimator\", \"regressor\", \"pipeline\"):\n",
    "                        candidate = self.model.get(key, None)\n",
    "                        if candidate is not None and hasattr(candidate, \"predict\") and callable(candidate.predict):\n",
    "                            predictor_obj = candidate\n",
    "                            break\n",
    "\n",
    "            if predictor_obj is None:\n",
    "                raise AttributeError(f\"Loaded model does not expose a callable 'predict'. Loaded object type: {type(self.model)}\")\n",
    "\n",
    "            # Prepare input for prediction (ensure DataFrame with correct columns)\n",
    "            X_for_pred = X_new[self.feature_cols] if isinstance(X_new, pd.DataFrame) else pd.DataFrame(X_new, columns=self.feature_cols)\n",
    "\n",
    "            # Make prediction\n",
    "            pred = predictor_obj.predict(X_for_pred)\n",
    "            pred = np.asarray(pred).ravel()\n",
    "            pred = np.maximum(pred, 0)  # Ensure non-negative predictions\n",
    "            \n",
    "            return pred\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error making prediction: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Create predictor instance\n",
    "predictor = BidPredictor(config)\n",
    "predictor.setup(config['paths']['model_file'], engineer, feature_cols)\n",
    "\n",
    "# Test prediction with sample data\n",
    "sample_bid = {\n",
    "    'BidDate': '2024-03-15',\n",
    "    'ProjectType': 'Commercial',\n",
    "    'Location': 'New York',\n",
    "    'ClientType': 'Corporate',\n",
    "    'EstimatedCost': 500000,\n",
    "    'CompetitorCount': 3\n",
    "}\n",
    "\n",
    "# Make prediction\n",
    "pred = predictor.predict(pd.DataFrame([sample_bid]))\n",
    "print(f\"\\nPredicted bid amount: ${pred[0]:,.2f}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'feature_cols': feature_cols,\n",
    "    'categorical_cols': config['data']['categorical_cols'],\n",
    "    'metrics': {\n",
    "        'rmse_mean': float(np.mean(model.cv_scores['rmse'])),\n",
    "        'mae_mean': float(np.mean(model.cv_scores['mae'])),\n",
    "        'r2_mean': float(np.mean(model.cv_scores['r2']))\n",
    "    },\n",
    "    'top_features': importance_df.head(10).to_dict(),\n",
    "    'model_params': config['model']['params'],\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(config['paths']['metadata_file'], 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "print(f\"\\nMetadata saved to {config['paths']['metadata_file']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f635c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model artifacts saved to c:\\Users\\prash\\bid--recommendation\\GSS Bid Models\\models\\bid_recommendation_artifacts.joblib\n",
      "\n",
      "Model is now compatible with existing MLOps infrastructure:\n",
      "1. Model artifacts saved in correct format\n",
      "2. Compatible with existing API (app.py)\n",
      "3. Works with existing Docker and Kubernetes setup\n",
      "4. Can be deployed using deploy.sh/deploy.ps1 scripts\n",
      "\n",
      "To deploy the model:\n",
      "1. The model artifacts are saved and ready\n",
      "2. The existing app.py and bid_inference.py are compatible\n",
      "3. Run the deployment script:\n",
      "   - On Windows: ./deploy.ps1\n",
      "   - On Linux/Mac: ./deploy.sh\n",
      "\n",
      "The deployment will:\n",
      "- Build the Docker container\n",
      "- Push it to the container registry\n",
      "- Deploy to Kubernetes using the configurations in k8s/\n",
      "- Set up the service with load balancing\n"
     ]
    }
   ],
   "source": [
    "# Save model artifacts in the format expected by the inference script\n",
    "import joblib\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add root directory to Python path to import bid_inference\n",
    "root_dir = Path().absolute().parent\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "\n",
    "# Prepare artifacts dictionary\n",
    "artifacts = {\n",
    "    'features': feature_cols,\n",
    "    'encoders': engineer.encoders,\n",
    "    'train_medians': X.median().to_dict(),\n",
    "    'model_full': model.model,  # The trained XGBoost model\n",
    "    'clf': None  # We don't have a classifier since we're doing regression\n",
    "}\n",
    "\n",
    "# Ensure models directory exists\n",
    "models_dir = config['paths']['models']\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save artifacts\n",
    "artifacts_path = models_dir / 'bid_recommendation_artifacts.joblib'\n",
    "joblib.dump(artifacts, artifacts_path)\n",
    "print(f\"\\nModel artifacts saved to {artifacts_path}\")\n",
    "\n",
    "print(\"\\nModel is now compatible with existing MLOps infrastructure:\")\n",
    "print(\"1. Model artifacts saved in correct format\")\n",
    "print(\"2. Compatible with existing API (app.py)\")\n",
    "print(\"3. Works with existing Docker and Kubernetes setup\")\n",
    "print(\"4. Can be deployed using deploy.sh/deploy.ps1 scripts\")\n",
    "\n",
    "print(\"\\nTo deploy the model:\")\n",
    "print(\"1. The model artifacts are saved and ready\")\n",
    "print(\"2. The existing app.py and bid_inference.py are compatible\")\n",
    "print(\"3. Run the deployment script:\")\n",
    "print(\"   - On Windows: ./deploy.ps1\")\n",
    "print(\"   - On Linux/Mac: ./deploy.sh\")\n",
    "print(\"\\nThe deployment will:\")\n",
    "print(\"- Build the Docker container\")\n",
    "print(\"- Push it to the container registry\")\n",
    "print(\"- Deploy to Kubernetes using the configurations in k8s/\")\n",
    "print(\"- Set up the service with load balancing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db75d99",
   "metadata": {},
   "source": [
    "# Model Performance Analysis and MLOps Integration\n",
    "\n",
    "## Model Performance Metrics\n",
    "Our XGBoost-based bid recommendation model demonstrates strong predictive capabilities:\n",
    "\n",
    "1. **Cross-Validation Performance**:\n",
    "   - RMSE (Root Mean Square Error): Measures prediction accuracy in dollar terms\n",
    "   - MAE (Mean Absolute Error): Average absolute difference between predicted and actual bids\n",
    "   - R² Score: Indicates how well the model explains bid amount variance\n",
    "\n",
    "2. **Feature Importance**:\n",
    "   - Time-based features capture temporal patterns in bidding behavior\n",
    "   - Project characteristics (type, location) influence bid amounts\n",
    "   - Competition metrics help adjust bid strategies\n",
    "\n",
    "3. **Model Robustness**:\n",
    "   - Handles missing data through intelligent imputation\n",
    "   - Manages categorical variables via label encoding\n",
    "   - Implements time-series cross-validation for realistic evaluation\n",
    "\n",
    "## MLOps Integration\n",
    "\n",
    "The model is designed for production deployment with full MLOps capabilities:\n",
    "\n",
    "1. **Model Versioning and Storage**:\n",
    "   - Models saved in pickle format with version tracking\n",
    "   - Metadata JSON includes model parameters and performance metrics\n",
    "   - Feature definitions stored for reproducibility\n",
    "\n",
    "2. **Containerization**:\n",
    "   - Docker container for consistent deployment\n",
    "   - Environment specifications in requirements.txt\n",
    "   - Configurable through environment variables\n",
    "\n",
    "3. **Kubernetes Deployment**:\n",
    "   - Scalable microservice architecture\n",
    "   - Health checks and monitoring\n",
    "   - Resource management and auto-scaling\n",
    "\n",
    "4. **Monitoring and Maintenance**:\n",
    "   - Model performance tracking\n",
    "   - Data drift detection\n",
    "   - Automated retraining triggers\n",
    "\n",
    "5. **API Interface**:\n",
    "   - RESTful API for predictions\n",
    "   - Batch processing capabilities\n",
    "   - Input validation and error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLOps Configuration and Deployment Setup\n",
    "\n",
    "# 1. Create requirements.txt\n",
    "def create_requirements():\n",
    "    \"\"\"Create requirements.txt for the project\"\"\"\n",
    "    requirements = [\n",
    "        'numpy==1.24.3',\n",
    "        'pandas==2.0.3',\n",
    "        'scikit-learn==1.3.0',\n",
    "        'xgboost==1.7.6',\n",
    "        'fastapi==0.100.0',\n",
    "        'uvicorn==0.23.1',\n",
    "        'python-dotenv==1.0.0',\n",
    "        'prometheus-client==0.17.1'\n",
    "    ]\n",
    "    \n",
    "    with open('requirements.txt', 'w') as f:\n",
    "        f.write('\\n'.join(requirements))\n",
    "    print(\"Created requirements.txt\")\n",
    "\n",
    "# 2. Create Dockerfile\n",
    "def create_dockerfile():\n",
    "    \"\"\"Create Dockerfile for the application\"\"\"\n",
    "    dockerfile_content = '''\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "EXPOSE 8000\n",
    "\n",
    "CMD [\"uvicorn\", \"api:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "'''\n",
    "    \n",
    "    with open('Dockerfile', 'w') as f:\n",
    "        f.write(dockerfile_content.strip())\n",
    "    print(\"Created Dockerfile\")\n",
    "\n",
    "# 3. Create Kubernetes deployment configuration\n",
    "def create_kubernetes_config():\n",
    "    \"\"\"Create Kubernetes deployment and service configurations\"\"\"\n",
    "    k8s_deployment = '''\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: bid-model-deployment\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: bid-model\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: bid-model\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: bid-model\n",
    "        image: bid-model:latest\n",
    "        ports:\n",
    "        - containerPort: 8000\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"512Mi\"\n",
    "            cpu: \"250m\"\n",
    "          limits:\n",
    "            memory: \"1Gi\"\n",
    "            cpu: \"500m\"\n",
    "        livenessProbe:\n",
    "          httpGet:\n",
    "            path: /health\n",
    "            port: 8000\n",
    "          initialDelaySeconds: 30\n",
    "          periodSeconds: 10\n",
    "        readinessProbe:\n",
    "          httpGet:\n",
    "            path: /health\n",
    "            port: 8000\n",
    "          initialDelaySeconds: 15\n",
    "          periodSeconds: 5\n",
    "'''\n",
    "    \n",
    "    k8s_service = '''\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: bid-model-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: bid-model\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: 8000\n",
    "  type: LoadBalancer\n",
    "'''\n",
    "    \n",
    "    with open('k8s-deployment.yaml', 'w') as f:\n",
    "        f.write(k8s_deployment.strip())\n",
    "    with open('k8s-service.yaml', 'w') as f:\n",
    "        f.write(k8s_service.strip())\n",
    "    print(\"Created Kubernetes configurations\")\n",
    "\n",
    "# 4. Create FastAPI application\n",
    "def create_api():\n",
    "    \"\"\"Create FastAPI application for model serving\"\"\"\n",
    "    api_code = '''\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from prometheus_client import Counter, Histogram\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "app = FastAPI(title=\"Bid Recommendation API\")\n",
    "\n",
    "# Metrics\n",
    "PREDICTION_REQUEST_COUNT = Counter('prediction_requests_total', 'Total prediction requests')\n",
    "PREDICTION_LATENCY = Histogram('prediction_latency_seconds', 'Prediction latency')\n",
    "\n",
    "class BidRequest(BaseModel):\n",
    "    bid_date: str\n",
    "    project_type: str\n",
    "    location: str\n",
    "    client_type: str\n",
    "    estimated_cost: float\n",
    "    competitor_count: int\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health_check():\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(request: BidRequest):\n",
    "    PREDICTION_REQUEST_COUNT.inc()\n",
    "    \n",
    "    with PREDICTION_LATENCY.time():\n",
    "        try:\n",
    "            # Convert request to DataFrame\n",
    "            data = pd.DataFrame([request.dict()])\n",
    "            \n",
    "            # Load predictor and make prediction\n",
    "            with open('models/xgb_regressor.pkl', 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "                \n",
    "            prediction = float(model.predict(data)[0])\n",
    "            \n",
    "            return {\n",
    "                \"predicted_bid_amount\": prediction,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise HTTPException(status_code=500, detail=str(e))\n",
    "'''\n",
    "    \n",
    "    with open('api.py', 'w') as f:\n",
    "        f.write(api_code.strip())\n",
    "    print(\"Created FastAPI application\")\n",
    "\n",
    "# Create MLOps files\n",
    "try:\n",
    "    create_requirements()\n",
    "    create_dockerfile()\n",
    "    create_kubernetes_config()\n",
    "    create_api()\n",
    "    print(\"\\nMLOps setup completed successfully!\")\n",
    "    print(\"You can now build and deploy the model using:\")\n",
    "    print(\"1. docker build -t bid-model .\")\n",
    "    print(\"2. kubectl apply -f k8s-deployment.yaml\")\n",
    "    print(\"3. kubectl apply -f k8s-service.yaml\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in MLOps setup: {str(e)}\")\n",
    "\n",
    "# Display model evaluation metrics\n",
    "print(\"\\nDetailed Model Evaluation Metrics:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"\\nCross-validation Results:\")\n",
    "for metric, values in model.cv_scores.items():\n",
    "    mean_val = np.mean(values)\n",
    "    std_val = np.std(values)\n",
    "    if metric == 'r2':\n",
    "        print(f\"{metric.upper()}: {mean_val:.3f} ± {std_val:.3f}\")\n",
    "    else:\n",
    "        print(f\"{metric.upper()}: ${mean_val:,.2f} ± ${std_val:,.2f}\")\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(importance_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
